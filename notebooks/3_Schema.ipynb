{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56119d8-fd30-4ece-80db-a51a17561949",
   "metadata": {},
   "source": [
    "# Changing the Schema in Apache Iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9da802-8ca3-45bc-96bd-be8beadf538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1784abed-86ca-445c-a811-8c16ce71268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Schema Evolution in Iceberg\")\n",
    "    .master(\"spark://spark:7077\") \n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c6584b-266f-4b16-9ec9-44296f4254d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|                  id|   bigint|   NULL|\n",
      "|                name|   string|   NULL|\n",
      "|               email|   string|   NULL|\n",
      "|# Partition Infor...|         |       |\n",
      "|          # col_name|data_type|comment|\n",
      "|               email|   string|   NULL|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"DESCRIBE TABLE ice.demo.customers;\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caff6c50-abaa-4735-8093-9bcdcb1f4720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"ALTER TABLE ice.demo.customers\n",
    "ADD COLUMN country STRING COMMENT 'ISO 3166-1 code' AFTER email;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24152373-9baa-40ba-b3ee-782ec580a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+---------------+\n",
      "|            col_name|data_type|        comment|\n",
      "+--------------------+---------+---------------+\n",
      "|                  id|   bigint|           NULL|\n",
      "|                name|   string|           NULL|\n",
      "|               email|   string|           NULL|\n",
      "|             country|   string|ISO 3166-1 code|\n",
      "|# Partition Infor...|         |               |\n",
      "|          # col_name|data_type|        comment|\n",
      "|               email|   string|           NULL|\n",
      "+--------------------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"DESCRIBE TABLE ice.demo.customers;\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78309f9-9a31-4ffb-879a-ce85a8ae3298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"UPDATE ice.demo.customers\n",
    "SET country = 'US'\n",
    "WHERE email LIKE '%@example.com';\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bea62ad5-8c24-462c-8392-6b75c5d6114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------------------+-------+\n",
      "| id|          name|               email|country|\n",
      "+---+--------------+--------------------+-------+\n",
      "| 22|      Zoe King|zoe.king@example.com|     US|\n",
      "| 21|   Jack Wilson|jack.wilson@examp...|     US|\n",
      "| 15|Isabella Rossi|isabella.rossi@ex...|     US|\n",
      "|  1|   Alice Smith|   alice@example.com|     US|\n",
      "|  2|   Bob Johnson|     bob@example.com|     US|\n",
      "| 12|  Lucas Martin|lucas.martin@exam...|     US|\n",
      "| 18|   Henry Scott|henry.scott@examp...|     US|\n",
      "| 16|  James Nguyen|james.nguyen@exam...|     US|\n",
      "|  5|    Maya Patel|maya.patel@exampl...|     US|\n",
      "|  7| Sofia Almeida|sofia.almeida@exa...|     US|\n",
      "| 19|  Aria Johnson|aria.johnson@exam...|     US|\n",
      "|  3|   Carol Adams|   carol@example.com|     US|\n",
      "| 20| Daniela Costa|daniela.costa@exa...|     US|\n",
      "|  4| Diego Ramirez|diego.ramirez@exa...|     US|\n",
      "| 17|    Mila Novak|mila.novak@exampl...|     US|\n",
      "|  8| Noah Williams|noah.williams@exa...|     US|\n",
      "|  9|  Ava Thompson|ava.thompson@exam...|     US|\n",
      "| 11| Olivia Garcia|olivia.garcia@exa...|     US|\n",
      "| 13| Emma Robinson|emma.robinson@exa...|     US|\n",
      "| 10|    Ethan Chen|ethan.chen@exampl...|     US|\n",
      "+---+--------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM ice.demo.customers\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937bf10e-3fb3-4490-9ab3-e8bcb43bb3e7",
   "metadata": {},
   "source": [
    "Let's go back before we edited the schema. Here is a list of operations in Iceberg\n",
    "\n",
    "| Operation            | Meaning                                                                 | Typical Trigger / Example                                     |\n",
    "|----------------------|-------------------------------------------------------------------------|---------------------------------------------------------------|\n",
    "| **append**           | Adds new data files to the table without touching existing ones         | `INSERT INTO ...`, batch ingest                               |\n",
    "| **overwrite**        | Replaces existing data files with new ones                              | `INSERT OVERWRITE`, Spark `.mode(\"overwrite\")` writes         |\n",
    "| **replace partitions** | Overwrites only affected partitions, leaving others intact            | Dynamic partition overwrite in Spark streaming                |\n",
    "| **delete**           | Removes rows from files (position deletes or equality deletes)          | `DELETE FROM table WHERE ...`                                 |\n",
    "| **update**           | Updates rows (internally: delete + insert of modified rows)             | `UPDATE table SET ... WHERE ...`                              |\n",
    "| **rewrite** (or `replace`) | Rewrites data files without logical changes (optimization/compaction) | `REWRITE DATA`, clustering, file compaction                   |\n",
    "| **fast-append**      | Fast ingestion, skips some validation checks (legacy mode)              | Optimized append from some engines                            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b5e95e-5bc2-40bd-ae15-7dc0bc7d739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+---------+\n",
      "|snapshot_id        |committed_at           |operation|\n",
      "+-------------------+-----------------------+---------+\n",
      "|6069821547749819533|2025-10-27 16:47:48.751|overwrite|\n",
      "|6233251210790417521|2025-10-27 16:46:37.232|append   |\n",
      "|5355358217514325757|2025-10-27 16:46:30.234|append   |\n",
      "+-------------------+-----------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT snapshot_id, committed_at, operation\n",
    "FROM ice.demo.customers.snapshots\n",
    "ORDER BY committed_at DESC\n",
    "LIMIT 5;\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b330cd8-3e58-4c0d-aa8b-561628b2db10",
   "metadata": {},
   "source": [
    "Notice at this point that there is the old schema since we had a different schema back then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8051b1b8-c45d-4582-86f2-74496a7e1e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------------------------+\n",
      "|id |name          |email                     |\n",
      "+---+--------------+--------------------------+\n",
      "|3  |Carol Adams   |carol@example.com         |\n",
      "|1  |Alice Smith   |alice@example.com         |\n",
      "|2  |Bob Johnson   |bob@example.com           |\n",
      "|22 |Zoe King      |zoe.king@example.com      |\n",
      "|21 |Jack Wilson   |jack.wilson@example.com   |\n",
      "|15 |Isabella Rossi|isabella.rossi@example.com|\n",
      "|12 |Lucas Martin  |lucas.martin@example.com  |\n",
      "|18 |Henry Scott   |henry.scott@example.com   |\n",
      "|16 |James Nguyen  |james.nguyen@example.com  |\n",
      "|5  |Maya Patel    |maya.patel@example.com    |\n",
      "|7  |Sofia Almeida |sofia.almeida@example.com |\n",
      "|19 |Aria Johnson  |aria.johnson@example.com  |\n",
      "|20 |Daniela Costa |daniela.costa@example.com |\n",
      "|4  |Diego Ramirez |diego.ramirez@example.com |\n",
      "|8  |Noah Williams |noah.williams@example.com |\n",
      "|17 |Mila Novak    |mila.novak@example.com    |\n",
      "|9  |Ava Thompson  |ava.thompson@example.com  |\n",
      "|11 |Olivia Garcia |olivia.garcia@example.com |\n",
      "|13 |Emma Robinson |emma.robinson@example.com |\n",
      "|10 |Ethan Chen    |ethan.chen@example.com    |\n",
      "+---+--------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT *\n",
    "FROM ice.demo.customers\n",
    "VERSION AS OF '6233251210790417521';\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc4ca027-05ab-432e-b24d-4940840ff73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
