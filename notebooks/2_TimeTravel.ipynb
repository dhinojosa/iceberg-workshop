{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56119d8-fd30-4ece-80db-a51a17561949",
   "metadata": {},
   "source": [
    "# Time Travel in Apache Iceberg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d8d630-74bb-4ef9-ae7d-f98ff5222000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3572590e-b10c-427b-8e1b-61d2b128d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Time Travel in Iceberg\")\n",
    "    .master(\"spark://spark:7077\") \n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1051d87-5718-48a1-af09-9088a6f60889",
   "metadata": {},
   "source": [
    "Let's view the snapshots, we had two batches, done at different times. So we should see two snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2a78cc-bfa5-4f80-84d3-9acb7ae1f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+---------+\n",
      "|snapshot_id        |committed_at           |operation|\n",
      "+-------------------+-----------------------+---------+\n",
      "|5355358217514325757|2025-10-27 16:46:30.234|append   |\n",
      "|6233251210790417521|2025-10-27 16:46:37.232|append   |\n",
      "+-------------------+-----------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT snapshot_id, committed_at, operation\n",
    "  FROM ice.demo.customers.snapshots\n",
    "  ORDER BY committed_at\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0cb84-58ad-4dc2-b531-67bd90348309",
   "metadata": {},
   "source": [
    "Let's now view the lineage of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5e3de2-fa4b-4c3d-a51d-7178f5c22318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2025-10-27 16:46:30.234|5355358217514325757|NULL               |true               |\n",
      "|2025-10-27 16:46:37.232|6233251210790417521|5355358217514325757|true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT made_current_at, snapshot_id, parent_id, is_current_ancestor\n",
    "  FROM ice.demo.customers.history\n",
    "  ORDER BY made_current_at\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c81c9-cff4-4c7b-b2c6-382cb15b6dcf",
   "metadata": {},
   "source": [
    "Now, let's go back in time by reverting the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b44a00cb-a95b-440e-a0ea-fe434e39789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-----------------+\n",
      "| id|       name|            email|\n",
      "+---+-----------+-----------------+\n",
      "|  3|Carol Adams|carol@example.com|\n",
      "|  1|Alice Smith|alice@example.com|\n",
      "|  2|Bob Johnson|  bob@example.com|\n",
      "+---+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "\n",
    "# Replace the following timestamp with one after the initial timestamp\n",
    "ts = \"2025-10-27 16:46:30.236\"\n",
    "\n",
    "df_ts = spark.sql(f\"\"\"\n",
    "  SELECT *\n",
    "  FROM ice.demo.customers\n",
    "  TIMESTAMP AS OF '{ts}'\n",
    "\"\"\")\n",
    "df_ts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc63b05-ca5f-4296-af8f-036e199ade22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+---------+\n",
      "|snapshot_id        |committed_at           |operation|\n",
      "+-------------------+-----------------------+---------+\n",
      "|6233251210790417521|2025-10-27 16:46:37.232|append   |\n",
      "|5355358217514325757|2025-10-27 16:46:30.234|append   |\n",
      "+-------------------+-----------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT snapshot_id, committed_at, operation\n",
    "FROM ice.demo.customers.snapshots\n",
    "ORDER BY committed_at DESC\n",
    "LIMIT 5;\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc4ca027-05ab-432e-b24d-4940840ff73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
